## Explainable AI Benchmark su CUB200-2011

## ðŸ“‚ Struttura 

```
project/
â”œâ”€â”€ CUB_200_2011/          # Cartella del dataset (da scaricare)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_utils.py      # Gestione dataset CUB200 e parsing metadati
â”‚   â”œâ”€â”€ model.py           # Definizione architettura (ResNet50)
â”‚   â”œâ”€â”€ explainers.py      # Wrapper per libreria Captum (IG, LIME, SHAP...) 
â”‚   â””â”€â”€ train.py           # Loop di training e validazione
â”œâ”€â”€ exploratory.ipynb      # Notebook per esperimenti preliminari
â””â”€â”€ README.md              
```

---

## ðŸ›  Moduli Implementati

### 1. Modello (`src/model.py`)

Utilizza il **Transfer Learning** partendo da una **ResNet50** pre-addestrata su **ImageNet**.

- **Modifica**: l'ultimo layer *Fully Connected* Ã¨ sostituito per adattarsi alle **200 classi** di uccelli del dataset CUB.
- **FunzionalitÃ **: supporta il **salvataggio/caricamento dei pesi** e l'**estrazione delle feature**.

---

### 2. Dati (`src/data_utils.py`)

Classe `CUBDataset` personalizzata che gestisce la complessitÃ  dei file di testo del **CUB200**:

- Incrocia `images.txt` e `image_class_labels.txt` per associare **immagini e label**.
- Gestisce le **trasformazioni** (resize, normalizzazione) necessarie per ResNet.

> **Nota**: include una funzione preliminare `get_part_annotations` per leggere le **coordinate delle parti anatomiche** (fondamentale per la fase di valutazione).

---

### 3. Explainers (`src/explainers.py`)

Un'architettura a oggetti basata su **Captum** che standardizza l'interfaccia per diversi metodi di spiegazione:

- **Gradient-based (White-box)**: Integrated Gradients, Saliency (Input Gradients).
- **Perturbation-based (Black-box)**: LIME, KernelSHAP.

**Output**: ogni explainer restituisce una **heatmap normalizzata**, pronta per la visualizzazione o la valutazione quantitativa.

---

### 4. Training (`src/train.py`)

Pipeline di **fine-tuning** veloce:

- Usa `CrossEntropyLoss` e ottimizzatore **Adam**.
- Salva automaticamente il **modello con la migliore accuratezza** sul validation set.

---

## ðŸš€ Come Eseguire

### Prerequisiti

```bash
pip install -r requirements.txt
```
Run exploratory notebook to test modules

---

## ðŸ“Š Stato del Progetto e Prossimi Passaggi (TODO)

Al momento il progetto Ã¨ in grado di:

- [x] Caricare correttamente il dataset e le label
- [x] Addestrare il modello con buone performance
- [x] Generare spiegazioni visive (heatmap) con **4 algoritmi diversi**

### Gap Analysis â€“ Requisiti mancanti per l'esame

Il requisito fondamentale del corso Ã¨ la **valutazione quantitativa della plausibilitÃ **.

- [ ] **Data Engineering**: aggiornare `CUBDataset` per restituire le **Ground Truth Masks** (maschere binarie create dalle coordinate delle parti anatomiche)
- [ ] **Metrica**: implementare una funzione di **Intersection over Union (IoU)** o **Energy Fraction** per misurare quanto la heatmap si sovrappone alla maschera delle parti reali
- [ ] **Benchmark**: eseguire uno script su tutto il test set per ottenere i punteggi finali (es. *"IG ha una plausibilitÃ  del 60% vs LIME 45%"*)

